from __future__ import annotations

import filecmp
import fnmatch
import re
import shutil
import socket
import subprocess
import tempfile
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import yaml
from rich.console import Console

from .paths import get_sync_config_path, get_sync_repo_dir
from .system import check_command_exists, get_os, run_command

console = Console()


CLAUDE_IGNORE_PATTERNS = [
    "debug/",
    "cache/",
    "paste-cache/",
    "downloads/",
    "stats-cache.json",
    ".DS_Store",
    "Thumbs.db",
    "desktop.ini",
    "shell-snapshots/",
    "session-env/",
    "ide/",
    "statsig/",
    "telemetry/",
    "plugins/cache/",
    "plugins/marketplaces/",
    "plugins/repos/",
    "plugins/install-counts-cache.json",
    "plugins/installed_plugins.json",
    "plugins/known_marketplaces.json",
]

CLAUDE_MEM_IGNORE_PATTERNS = ["logs/", "worker.pid", "*.db-wal", "*.db-shm"]

GLOBAL_IGNORE_PATTERNS = [".DS_Store", "Thumbs.db", "desktop.ini"]


def default_sync_directories() -> list[dict[str, Any]]:
    return [
        {
            "path": "~/.claude",
            "repo_subdir": "claude",
            "ignore_profile": "claude",
            "custom_ignore": [],
        },
        {
            "path": "~/.claude-mem",
            "repo_subdir": "claude-mem",
            "ignore_profile": "claude-mem",
            "custom_ignore": [],
        },
    ]


def to_tilde_path(path: Path | str) -> str:
    resolved = Path(path).expanduser()
    home = Path.home()
    try:
        rel = resolved.relative_to(home)
        return f"~/{rel.as_posix()}"
    except ValueError:
        return str(resolved)


def get_ignore_patterns(
    profile: str, custom_ignore: list[str] | None = None
) -> list[str]:
    if profile == "claude":
        return list(CLAUDE_IGNORE_PATTERNS)
    if profile == "claude-mem":
        return list(CLAUDE_MEM_IGNORE_PATTERNS)
    if profile == "custom":
        return list(custom_ignore or [])

    console.print(
        f"[yellow]警告：未知 ignore profile '{profile}'，將使用空排除清單[/yellow]"
    )
    return []


def load_sync_config() -> dict[str, Any]:
    config_path = get_sync_config_path()
    if not config_path.exists():
        raise FileNotFoundError(
            f"找不到 sync 設定檔：{config_path}。請先執行 `ai-dev sync init`"
        )

    with open(config_path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}

    if not isinstance(data, dict):
        raise ValueError("sync.yaml 格式錯誤：必須為 YAML object")

    data.setdefault("version", "1")
    data.setdefault("remote", "")
    data.setdefault("last_sync", None)
    data.setdefault("directories", [])
    return data


def save_sync_config(config: dict[str, Any]) -> None:
    config_path = get_sync_config_path()
    config_path.parent.mkdir(parents=True, exist_ok=True)
    with open(config_path, "w", encoding="utf-8") as f:
        yaml.dump(
            config, f, allow_unicode=True, default_flow_style=False, sort_keys=False
        )


def prefix_excludes(repo_subdir: str, excludes: list[str]) -> list[str]:
    prefix = repo_subdir.strip("/")
    if not prefix:
        return []

    prefixed: list[str] = []
    for pattern in excludes:
        normalized = pattern.strip().lstrip("/")
        if not normalized:
            continue
        prefixed.append(f"{prefix}/{normalized}")
    return prefixed


def generate_gitignore(directories: list[dict[str, Any]]) -> str:
    lines = ["# Generated by ai-dev sync. Do not edit manually.", ""]
    seen: set[str] = set()

    for item in directories:
        repo_subdir = str(item.get("repo_subdir", "")).strip()
        if not repo_subdir:
            continue

        profile = str(item.get("ignore_profile", "custom"))
        custom_ignore = item.get("custom_ignore") or []
        excludes = get_ignore_patterns(profile, custom_ignore)
        prefixed = prefix_excludes(repo_subdir, excludes)
        if not prefixed:
            continue

        lines.append(f"# {repo_subdir}/ profile: {profile}")
        for rule in prefixed:
            if rule in seen:
                continue
            seen.add(rule)
            lines.append(rule)
        lines.append("")

    lines.append("# Global excludes")
    for rule in GLOBAL_IGNORE_PATTERNS:
        if rule in seen:
            continue
        seen.add(rule)
        lines.append(rule)

    return "\n".join(lines).rstrip() + "\n"


def generate_gitattributes() -> str:
    lines = [
        "# Generated by ai-dev sync. Do not edit manually.",
        "",
        "*.jsonl merge=union",
        "*.md text eol=lf",
    ]
    return "\n".join(lines).rstrip() + "\n"


def write_gitignore(repo_dir: Path | str, directories: list[dict[str, Any]]) -> Path:
    repo_root = Path(repo_dir).expanduser()
    repo_root.mkdir(parents=True, exist_ok=True)
    gitignore_path = repo_root / ".gitignore"
    gitignore_path.write_text(generate_gitignore(directories), encoding="utf-8")
    return gitignore_path


def write_gitattributes(repo_dir: Path | str) -> Path:
    repo_root = Path(repo_dir).expanduser()
    repo_root.mkdir(parents=True, exist_ok=True)
    gitattributes_path = repo_root / ".gitattributes"
    gitattributes_path.write_text(generate_gitattributes(), encoding="utf-8")
    return gitattributes_path


def _normalize_pattern(pattern: str) -> str:
    return pattern.strip().replace("\\", "/")


def _matches_pattern(rel_path: str, pattern: str) -> bool:
    normalized_path = rel_path.strip("/")
    normalized_pattern = _normalize_pattern(pattern).lstrip("/")
    if not normalized_pattern:
        return False

    if normalized_pattern.endswith("/"):
        base = normalized_pattern.rstrip("/")
        return normalized_path == base or normalized_path.startswith(f"{base}/")

    if fnmatch.fnmatch(normalized_path, normalized_pattern):
        return True

    return fnmatch.fnmatch(Path(normalized_path).name, normalized_pattern)


def _is_excluded(rel_path: str, excludes: list[str]) -> bool:
    return any(_matches_pattern(rel_path, pattern) for pattern in excludes)


def _parse_rsync_stat(output: str, field: str) -> int:
    pattern = rf"{re.escape(field)}:\s*([0-9]+)"
    match = re.search(pattern, output)
    if not match:
        return 0
    return int(match.group(1))


def _sync_directory_rsync(
    src: Path, dst: Path, excludes: list[str], delete: bool = True
) -> dict[str, Any]:
    with tempfile.NamedTemporaryFile(mode="w", encoding="utf-8", delete=False) as tmp:
        for pattern in excludes:
            tmp.write(pattern)
            tmp.write("\n")
        exclude_file = tmp.name

    try:
        command = [
            "rsync",
            "-av",
            "--stats",
            "--exclude-from",
            exclude_file,
        ]
        if delete:
            command.append("--delete")
        command.extend([f"{src}/", f"{dst}/"])

        result = subprocess.run(command, capture_output=True, text=True, check=False)
        if result.returncode != 0:
            message = result.stderr.strip() or "rsync 同步失敗"
            raise RuntimeError(message)

        output = result.stdout
        return {
            "added": 0,
            "updated": _parse_rsync_stat(output, "Number of regular files transferred"),
            "deleted": _parse_rsync_stat(output, "Number of deleted files"),
            "files": _parse_rsync_stat(output, "Number of files"),
            "method": "rsync",
        }
    finally:
        Path(exclude_file).unlink(missing_ok=True)


def _files_equal(left: Path, right: Path) -> bool:
    try:
        return filecmp.cmp(left, right, shallow=False)
    except OSError:
        return False


def _collect_files(root: Path, excludes: list[str]) -> dict[str, Path]:
    files: dict[str, Path] = {}
    if not root.exists():
        return files

    for path in root.rglob("*"):
        if not path.is_file():
            continue
        rel = path.relative_to(root).as_posix()
        if _is_excluded(rel, excludes):
            continue
        files[rel] = path
    return files


def _cleanup_empty_dirs(root: Path) -> None:
    if not root.exists():
        return
    for path in sorted(root.rglob("*"), key=lambda item: len(item.parts), reverse=True):
        if not path.is_dir():
            continue
        try:
            path.rmdir()
        except OSError:
            continue


def _sync_directory_shutil(
    src: Path, dst: Path, excludes: list[str], delete: bool = True
) -> dict[str, Any]:
    src_files = _collect_files(src, excludes)
    dst_files = _collect_files(dst, excludes)

    added = 0
    updated = 0
    deleted = 0

    for rel, src_file in src_files.items():
        dst_file = dst / rel
        dst_file.parent.mkdir(parents=True, exist_ok=True)

        if not dst_file.exists():
            shutil.copy2(src_file, dst_file)
            added += 1
            continue

        if not _files_equal(src_file, dst_file):
            shutil.copy2(src_file, dst_file)
            updated += 1

    if delete:
        for rel, dst_file in dst_files.items():
            if rel in src_files:
                continue
            dst_file.unlink(missing_ok=True)
            deleted += 1
        _cleanup_empty_dirs(dst)

    return {
        "added": added,
        "updated": updated,
        "deleted": deleted,
        "files": len(src_files),
        "method": "shutil",
    }


def sync_directory(
    src: Path | str,
    dst: Path | str,
    excludes: list[str],
    delete: bool = True,
) -> dict[str, Any]:
    src_path = Path(src).expanduser()
    dst_path = Path(dst).expanduser()

    if not src_path.exists():
        raise FileNotFoundError(f"來源目錄不存在：{src_path}")

    dst_path.mkdir(parents=True, exist_ok=True)

    if get_os() != "windows" and check_command_exists("rsync"):
        return _sync_directory_rsync(src_path, dst_path, excludes, delete=delete)

    return _sync_directory_shutil(src_path, dst_path, excludes, delete=delete)


def _git_has_remote(repo_dir: Path, remote_name: str) -> bool:
    result = subprocess.run(
        ["git", "remote", "get-url", remote_name],
        cwd=str(repo_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    return result.returncode == 0


def _git_set_remote(repo_path: Path, remote_url: str) -> None:
    if _git_has_remote(repo_path, "origin"):
        run_command(
            ["git", "remote", "set-url", "origin", remote_url], cwd=str(repo_path)
        )
    else:
        run_command(
            ["git", "remote", "add", "origin", remote_url], cwd=str(repo_path)
        )


def _git_remote_has_branch(repo_path: Path, branch: str) -> bool:
    result = subprocess.run(
        ["git", "ls-remote", "--heads", "origin", branch],
        cwd=str(repo_path),
        capture_output=True,
        text=True,
        check=False,
    )
    return result.returncode == 0 and branch in result.stdout


def git_init_or_clone(repo_dir: Path | str, remote_url: str) -> str:
    """初始化或 clone sync repo。回傳 'existing' | 'cloned' | 'initialized'。"""
    repo_path = Path(repo_dir).expanduser()

    # 已有 .git → 更新 remote URL 並對齊遠端
    if (repo_path / ".git").exists():
        _git_set_remote(repo_path, remote_url)
        # fetch 遠端並對齊，避免 stale 狀態導致 push 失敗
        subprocess.run(
            ["git", "fetch", "origin"],
            cwd=str(repo_path),
            capture_output=True,
            text=True,
            check=False,
        )
        if _git_remote_has_branch(repo_path, "main"):
            # 設定 upstream tracking
            subprocess.run(
                ["git", "branch", "--set-upstream-to=origin/main", "main"],
                cwd=str(repo_path),
                capture_output=True,
                check=False,
            )
            # rebase 本地變更到遠端之上
            subprocess.run(
                ["git", "rebase", "origin/main"],
                cwd=str(repo_path),
                capture_output=True,
                check=False,
            )
        return "existing"

    repo_path.parent.mkdir(parents=True, exist_ok=True)

    # 嘗試 clone
    if not repo_path.exists():
        clone_result = subprocess.run(
            ["git", "clone", remote_url, str(repo_path)],
            capture_output=True,
            text=True,
            check=False,
        )
        if clone_result.returncode == 0:
            return "cloned"
        # clone 失敗，清理殘留目錄
        if repo_path.exists():
            shutil.rmtree(repo_path)

    # fallback: init + fetch
    repo_path.mkdir(parents=True, exist_ok=True)
    run_command(["git", "init"], cwd=str(repo_path))
    _git_set_remote(repo_path, remote_url)

    # 嘗試 fetch 遠端內容
    fetch_result = subprocess.run(
        ["git", "fetch", "origin"],
        cwd=str(repo_path),
        capture_output=True,
        text=True,
        check=False,
    )

    if fetch_result.returncode == 0 and _git_remote_has_branch(repo_path, "main"):
        # 遠端有 main → 以遠端為基礎
        run_command(
            ["git", "checkout", "-b", "main", "--track", "origin/main"],
            cwd=str(repo_path),
            check=False,
        )
        return "cloned"

    # 遠端為空或 fetch 失敗 → 本地全新開始
    run_command(["git", "branch", "-M", "main"], cwd=str(repo_path), check=False)
    return "initialized"


def git_add_commit(repo_dir: Path | str, message: str) -> bool:
    repo_path = Path(repo_dir).expanduser()
    run_command(["git", "add", "-A"], cwd=str(repo_path))

    has_changes = subprocess.run(
        ["git", "diff", "--cached", "--quiet"],
        cwd=str(repo_path),
        check=False,
    )
    if has_changes.returncode == 0:
        return False

    result = run_command(
        ["git", "commit", "-m", message],
        cwd=str(repo_path),
        check=False,
    )
    return result.returncode == 0


def git_pull_rebase(repo_dir: Path | str) -> bool:
    repo_path = Path(repo_dir).expanduser()
    if not _has_upstream(repo_path):
        return True  # 尚未設定 upstream，跳過 pull
    result = run_command(["git", "pull", "--rebase"], cwd=str(repo_path), check=False)
    return result.returncode == 0


def _has_upstream(repo_dir: Path) -> bool:
    result = subprocess.run(
        ["git", "rev-parse", "--abbrev-ref", "--symbolic-full-name", "@{upstream}"],
        cwd=str(repo_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    return result.returncode == 0


def git_push(repo_dir: Path | str) -> bool:
    repo_path = Path(repo_dir).expanduser()
    if _has_upstream(repo_path):
        cmd = ["git", "push"]
    else:
        cmd = ["git", "push", "-u", "origin", "main"]
    result = run_command(cmd, cwd=str(repo_path), check=False)
    return result.returncode == 0


def git_status_summary(repo_dir: Path | str) -> dict[str, int]:
    repo_path = Path(repo_dir).expanduser()

    local_changes_result = subprocess.run(
        ["git", "status", "--porcelain"],
        cwd=str(repo_path),
        capture_output=True,
        text=True,
        check=False,
    )
    if local_changes_result.returncode == 0:
        local_changes = len(
            [line for line in local_changes_result.stdout.splitlines() if line.strip()]
        )
    else:
        local_changes = 0

    if _has_upstream(repo_path):
        behind_result = subprocess.run(
            ["git", "rev-list", "--count", "HEAD..@{upstream}"],
            cwd=str(repo_path),
            capture_output=True,
            text=True,
            check=False,
        )
        if behind_result.returncode == 0:
            try:
                behind_count = int(behind_result.stdout.strip() or "0")
            except ValueError:
                behind_count = 0
        else:
            behind_count = 0
    else:
        behind_count = 0

    return {"local_changes": local_changes, "behind_count": behind_count}


def get_hostname() -> str:
    return socket.gethostname()


def get_timestamp() -> str:
    return datetime.now().strftime("%Y-%m-%d-%H%M")


def generate_sync_commit_message() -> str:
    return f"sync: {get_hostname()} {get_timestamp()}"


def now_iso8601() -> str:
    return datetime.now(timezone.utc).isoformat()


def count_directory_changes(
    source_dir: Path | str,
    target_dir: Path | str,
    excludes: list[str],
) -> int:
    source_files = _collect_files(Path(source_dir).expanduser(), excludes)
    target_files = _collect_files(Path(target_dir).expanduser(), excludes)

    source_set = set(source_files.keys())
    target_set = set(target_files.keys())

    added_or_removed = len(source_set.symmetric_difference(target_set))
    modified = 0
    for rel in source_set.intersection(target_set):
        if not _files_equal(source_files[rel], target_files[rel]):
            modified += 1

    return added_or_removed + modified


def make_repo_subdir_name(path: Path | str, existing: set[str]) -> str:
    target = Path(path).expanduser()
    raw_name = target.name or "sync-dir"
    base = re.sub(r"[^A-Za-z0-9._-]+", "-", raw_name).strip("-").lower() or "sync-dir"

    candidate = base
    index = 2
    while candidate in existing:
        candidate = f"{base}-{index}"
        index += 1
    return candidate


def ensure_sync_repo_dir() -> Path:
    repo_dir = get_sync_repo_dir()
    repo_dir.mkdir(parents=True, exist_ok=True)
    return repo_dir
